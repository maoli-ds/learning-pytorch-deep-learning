{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0183193d",
      "metadata": {
        "id": "0183193d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchtext.datasets import IMDB\n",
        "from torch.utils.data.dataset import random_split\n",
        "import os\n",
        "import sys\n",
        "import tarfile\n",
        "import time\n",
        "import urllib.request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2e529abb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e529abb",
        "outputId": "15897988-a7e9-4786-91e3-e06c330f45bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% | 80.23 MB | 3.66 MB/s | 21.93 sec elapsed"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "source = 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
        "target = 'aclImdb_v1.tar.gz'\n",
        "\n",
        "if os.path.exists(target):\n",
        "    os.remove(target)\n",
        "\n",
        "def reporthook(count, block_size, total_size):\n",
        "    global start_time\n",
        "    if count == 0:\n",
        "        start_time = time.time()\n",
        "        return\n",
        "    duration = time.time() - start_time\n",
        "    progress_size = int(count * block_size)\n",
        "    speed = progress_size / (1024.**2 * duration+0.01)\n",
        "    percent = count * block_size * 100. / total_size\n",
        "\n",
        "    sys.stdout.write(f'\\r{int(percent)}% | {progress_size / (1024.**2):.2f} MB '\n",
        "                     f'| {speed:.2f} MB/s | {duration:.2f} sec elapsed')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "\n",
        "if not os.path.isdir('aclImdb') and not os.path.isfile('aclImdb_v1.tar.gz'):\n",
        "    urllib.request.urlretrieve(source, target, reporthook)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "46e3ab4f",
      "metadata": {
        "id": "46e3ab4f"
      },
      "outputs": [],
      "source": [
        "if not os.path.isdir('aclImdb'):\n",
        "\n",
        "    with tarfile.open(target, 'r:gz') as tar:\n",
        "        tar.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyprind"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76ScGnAoZSuQ",
        "outputId": "356dac6c-e86f-4353-cfae-79bd403305b0"
      },
      "id": "76ScGnAoZSuQ",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyprind in /usr/local/lib/python3.7/dist-packages (2.11.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "fa229413",
      "metadata": {
        "id": "fa229413"
      },
      "outputs": [],
      "source": [
        "import pyprind\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "fb653b62",
      "metadata": {
        "id": "fb653b62"
      },
      "outputs": [],
      "source": [
        "basepath = 'aclImdb'\n",
        "\n",
        "labels = {'pos': 1, 'neg': 0}\n",
        "pbar = pyprind.ProgBar(50000, stream=sys.stdout)\n",
        "df = pd.DataFrame()\n",
        "for s in ('test', 'train'):\n",
        "    for l in ('pos', 'neg'):\n",
        "        path = os.path.join(basepath, s, l)\n",
        "        for file in sorted(os.listdir(path)):\n",
        "            with open(os.path.join(path, file), \n",
        "                      'r', encoding='utf-8') as infile:\n",
        "                txt = infile.read()\n",
        "            df = df.append([[txt, labels[l]]], \n",
        "                           ignore_index=True)\n",
        "            pbar.update()\n",
        "df.columns = ['review', 'sentiment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "9179bf9a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "9179bf9a",
        "outputId": "1446c1b1-791f-4691-fb56-7012ed32a8fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  review  sentiment\n",
              "11841  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
              "19602  OK... so... I really like Kris Kristofferson a...          0\n",
              "45519  ***SPOILER*** Do not read this, if you think a...          0\n",
              "25747  hi for all the people who have seen this wonde...          1\n",
              "42642  I recently bought the DVD, forgetting just how...          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-19783533-b4cb-4aa4-8a4a-1eca2f25512a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11841</th>\n",
              "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19602</th>\n",
              "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45519</th>\n",
              "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25747</th>\n",
              "      <td>hi for all the people who have seen this wonde...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42642</th>\n",
              "      <td>I recently bought the DVD, forgetting just how...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19783533-b4cb-4aa4-8a4a-1eca2f25512a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-19783533-b4cb-4aa4-8a4a-1eca2f25512a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-19783533-b4cb-4aa4-8a4a-1eca2f25512a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "df = df.reindex(np.random.permutation(df.index))\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8651daea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8651daea",
        "outputId": "de41b4a4-2ea6-4935-e53f-aaef94257a46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of positive/negative reviews are 25000/25000\n"
          ]
        }
      ],
      "source": [
        "df.reset_index(inplace=True)\n",
        "print('Number of positive/negative reviews are {}/{}'.format(df.sentiment.sum(), df.shape[0]-df.sentiment.sum()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ad89be22",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ad89be22",
        "outputId": "67de9742-3c01-41c7-cea9-46a6c8e36dab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment\n",
              "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
              "1  OK... so... I really like Kris Kristofferson a...          0\n",
              "2  ***SPOILER*** Do not read this, if you think a...          0\n",
              "3  hi for all the people who have seen this wonde...          1\n",
              "4  I recently bought the DVD, forgetting just how...          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d5d7053-e1a4-4e8f-91ad-d9673808a2a9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hi for all the people who have seen this wonde...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I recently bought the DVD, forgetting just how...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d5d7053-e1a4-4e8f-91ad-d9673808a2a9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0d5d7053-e1a4-4e8f-91ad-d9673808a2a9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0d5d7053-e1a4-4e8f-91ad-d9673808a2a9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df.drop(columns=['index'], inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "1315e0b8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1315e0b8",
        "outputId": "e026e0fe-3b7f-4794-9c0f-8b30095a4765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In 1974, the teenager Martha Moxley (Maggie Grace) moves to the high-class area of Belle Haven, Greenwich, Connecticut. On the Mischief Night, eve of Halloween, she was murdered in the backyard of her house and her murder remained unsolved. Twenty-two years later, the writer Mark Fuhrman (Christopher Meloni), who is a former LA detective that has fallen in disgrace for perjury in O.J. Simpson trial and moved to Idaho, decides to investigate the case with his partner Stephen Weeks (Andrew Mitchell) with the purpose of writing a book. The locals squirm and do not welcome them, but with the support of the retired detective Steve Carroll (Robert Forster) that was in charge of the investigation in the 70's, they discover the criminal and a net of power and money to cover the murder.<br /><br />\"Murder in Greenwich\" is a good TV movie, with the true story of a murder of a fifteen years old girl that was committed by a wealthy teenager whose mother was a Kennedy. The powerful and rich family used their influence to cover the murder for more than twenty years. However, a snoopy detective and convicted perjurer in disgrace was able to disclose how the hideous crime was committed. The screenplay shows the investigation of Mark and the last days of Martha in parallel, but there is a lack of the emotion in the dramatization. My vote is seven.<br /><br />Title (Brazil): Not Available\n",
            "--------------------------------------------------------------------------------\n",
            "OK... so... I really like Kris Kristofferson and his usual easy going delivery of lines in his movies. Age has helped him with his soft spoken low energy style and he will steal a scene effortlessly. But, Disappearance is his misstep. Holy Moly, this was a bad movie! <br /><br />I must give kudos to the cinematography and and the actors, including Kris, for trying their darndest to make sense from this goofy, confusing story! None of it made sense and Kris probably didn't understand it either and he was just going through the motions hoping someone would come up to him and tell him what it was all about! <br /><br />I don't care that everyone on this movie was doing out of love for the project, or some such nonsense... I've seen low budget movies that had a plot for goodness sake! This had none, zilcho, nada, zippo, empty of reason... a complete waste of good talent, scenery and celluloid! <br /><br />I rented this piece of garbage for a buck, and I want my money back! I want my 2 hours back I invested on this Grade F waste of my time! Don't watch this movie, or waste 1 minute of your valuable time while passing through a room where it's playing or even open up the case that is holding the DVD! Believe me, you'll thank me for the advice!\n",
            "--------------------------------------------------------------------------------\n",
            "***SPOILER*** Do not read this, if you think about watching that movie, although it would be a waste of time. (By the way: The plot is so predictable that it does not make any difference if you read this or not anyway)<br /><br />If you are wondering whether to see \"Coyote Ugly\" or not: don't! It's not worth either the money for the ticket or the VHS / DVD. A typical \"Chick-Feel-Good-Flick\", one could say. The plot itself is as shallow as it can be, a ridiculous and uncritical version of the American Dream. The young good-looking girl from a small town becoming a big success in New York. The few desperate attempts of giving the movie any depth fail, such as the \"tragic\" accident of the father, the \"difficulties\" of Violet's relationship with her boyfriend, and so on. McNally (Director) tries to arouse the audience's pity and sadness put does not have any chance to succeed in this attempt due to the bad script and the shallow acting. Especially Piper Perabo completely fails in convincing one of \"Jersey's\" fear of singing in front of an audience. The only good (and quite funny thing) about \"Coyote Ugly\" is John Goodman, who represents the small ray of hope of this movie.<br /><br />I was very astonished, that Jerry Bruckheimer produced this movie. First \"Gone In 60 Seconds\" and now this... what happened to great movies like \"The Rock\" and \"Con Air\"? THAT was true Bruckheimer stuff.<br /><br />If you are looking for a superficial movie with good looking women just to have a relaxed evening, you should better go and see \"Charlie's Angels\" (it's much more funny, entertaining and self-ironic) instead of this flick.<br /><br />Two thumbs down (3 out of 10).\n",
            "--------------------------------------------------------------------------------\n",
            "hi for all the people who have seen this wonderful movie im sure thet you would have liked it as much as i. i love the songs once you have seen the show you can sing along as though you are part of the show singing and dancing . dancing and singing. the song ONE is an all time fave musical song too and the strutters at the end with the mirror its so oh you have to watch this one\n",
            "--------------------------------------------------------------------------------\n",
            "I recently bought the DVD, forgetting just how much I hated the movie version of \"A Chorus Line.\" Every change the director Attenborough made to the story failed.<br /><br />By making the Director-Cassie relationship so prominent, the entire ensemble-premise of the musical sails out the window.<br /><br />Some of the musical numbers are sped up and rushed. The show's hit song gets the entire meaning shattered when it is given to Cassie's character.<br /><br />The overall staging is very self-conscious.<br /><br />The only reason I give it a 2, is because a few of the great numbers are still able to be enjoyed despite the film's attempt to squeeze every bit of joy and spontaneity out of it.\n",
            "--------------------------------------------------------------------------------\n",
            "Leave it to Braik to put on a good show. Finally he and Zorak are living their own lives outside of Spac Ghost Coast To Coast. I have to say that I love both of these shows a whole lot. They are completely what started Adult Swim. Brak made it big with an album that came out in the year 2000. It may not have been platinum, but his show was really popular to tons of people out there that love Adult Swims shows. I have to say that out of all the Adult Swim shows with no plot, this has to be the one with the most none plot ever made. That is why I like it so much, it is just such a classic in the Adult Swim history. I believe this is just such a great show, if you don't like it. Hey there were tons who hated it and tons who loved it.\n",
            "--------------------------------------------------------------------------------\n",
            "Nathan Detroit (Frank Sinatra) is the manager of the New York's longest- established floating craps game, and he needs $1000 to secure a new location. Confident of his odds, he bets the city's highest-roller, Sky Masterson (Marlon Brando), that he can't woo uptight missionary Sarah Brown (Jean Simmons). 'Guys and Dolls (1955)' is such a great musical because it deftly blends the contrasting styles of film and stage. During a dazzling opening sequence, crowds of pedestrians move in rhythm, stopping and starting as though responding to backstage cues. Even the walking movements themselves are stylised and angular, halfway between a walk and a dance. Mankiewicz's New York City is a glittering flurry of art deco colour and movement, a fantasy world so completely removed from reality that even the business of underground gambling and criminal thuggery seems perfectly genial. <br /><br />As I write this review, I've just received word that Jean Simmons has passed away, age 80. This, unbelievably, was the first time I'd seen her in a film, yet she dazzled me from the beginning. Her idealistic and sexually-repressed Sarah comes out of her shell following an alcohol binge in Havana, letting loose with an adorably playful rendition of \"If I Were A Bell.\" Even though both Simmons and Brando were non-singers, producer Sam Goldwyn decided not to dub their vocals, contending that \"maybe you don't sound so good, but at least it's you.\" Despite Goldwyn's backhanded confidence, the pair both do well to carry entire musical numbers themselves. Simmons suggests the same child-like liveliness that Audrey Hepburn might have brought to the role, and Brando exudes such self-assurance and charisma that it doesn't matter that his singing voice isn't quite there.\n",
            "--------------------------------------------------------------------------------\n",
            "To understand \"Crash Course\" in the right context, you must understand the 80's in TV. Most TV shows didn't have any point. The sitcom outpopulated the drama at least 3 to 1. They were still figuring out where the lines were so that they could cross them. (TV Shows like \"Hail to the Chief\" was quite the bold step!) This made-for-TV movie \"Crash Course\" featured an All-Star cast, bringing together members from all the 80's classics: \"227\", \"Family Ties\", \"Who's the Boss?\", et al. Directors must've had a certain penchant for those all-star movies then. Still, this movie offered very light fare and a simplistic view of heroism and maturity. And that's not bad sometimes. Viva Soleil Moon Frye.\n",
            "--------------------------------------------------------------------------------\n",
            "I've been impressed with Chavez's stance against globalisation for sometime now, but it wasn't until I saw the film at the Amsterdam documentary international film festival that I realize what he has really achieved. This film tells the story of coup/conspiracy by Venezuela's elite, the oil companies and oil loving corrupt western governments, to remove democratically elected president Chavez, and return Venezuela back to a brutal dictatorship. This film is must for anyone who believes in freedom and justice, and is also a lesson to the rest of world ! I commend the people of Venezuela for taking matter into their own hands, and saving their country from the likes of Halliburton and the Bush regime.\n",
            "--------------------------------------------------------------------------------\n",
            "This movie is directed by Renny Harlin the finnish miracle. Stallone is Gabe Walker. Cat and Mouse on the mountains with ruthless terrorists. Renny Harlin knows how to direct actionmovie. Stallone needed this role to get back on track. Snowy mountain is very good place for action movie and who is better to direct movie where is snow, ice, cold and bad weather than finnish man. Action is good! Music in the film is spectacular. The bad guy is John Litghow, other stars Micheal Rooker ( The portrait of serialkiller), Janine Turner ( Strong Medicine). The is placed in beautiful place and it is very exciting movie. Overall good movie ****/*****<br /><br />Remember Extreme ääliöt: special collectors edition, with good extras. Comig soon in Finland straight to video.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for i in range(0,10):\n",
        "    print(df['review'].values[i])\n",
        "    print('-'*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "07b2f42a",
      "metadata": {
        "id": "07b2f42a"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def preprocessor(text):\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
        "                           text)\n",
        "    text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
        "            ' '.join(emoticons).replace('-', ''))\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "5887f27b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "5887f27b",
        "outputId": "9dddf62c-07d8-4451-8113-428812c35e57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'this movie is directed by renny harlin the finnish miracle stallone is gabe walker cat and mouse on the mountains with ruthless terrorists renny harlin knows how to direct actionmovie stallone needed this role to get back on track snowy mountain is very good place for action movie and who is better to direct movie where is snow ice cold and bad weather than finnish man action is good music in the film is spectacular the bad guy is john litghow other stars micheal rooker the portrait of serialkiller janine turner strong medicine the is placed in beautiful place and it is very exciting movie overall good movie remember extreme ääliöt special collectors edition with good extras comig soon in finland straight to video '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "preprocessor(df['review'].values[9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "92b4c0fd",
      "metadata": {
        "id": "92b4c0fd"
      },
      "outputs": [],
      "source": [
        "df['review'] = df['review'].apply(preprocessor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "5fcfb205",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fcfb205",
        "outputId": "07beaa46-1e4c-4ff9-9cdb-1d7ed80d488d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "porter = PorterStemmer()\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "def tokenizer(text):\n",
        "    return text.split()\n",
        "\n",
        "\n",
        "def tokenizer_porter(text):\n",
        "    return [porter.stem(word) for word in text.split()]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "60a3df94",
      "metadata": {
        "id": "60a3df94"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "996e224d",
      "metadata": {
        "id": "996e224d"
      },
      "outputs": [],
      "source": [
        "tfidf = TfidfVectorizer(strip_accents=None,\n",
        "                        lowercase=False,\n",
        "                        preprocessor=None, max_features=1000)\n",
        "\n",
        "lr_tfidf = Pipeline([('vect', tfidf),\n",
        "                     ('clf', LogisticRegression(solver='liblinear'))])\n",
        "\n",
        "small_param_grid = {'vect__ngram_range': [(1, 1), (2, 3)],\n",
        "                     'vect__stop_words': [stop, None],\n",
        "                     'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
        "                     'clf__penalty': ['l1','l2'],\n",
        "                     'clf__C': [1.0, 10.0]}\n",
        "    \n",
        "gs_lr_tfidf = GridSearchCV(lr_tfidf, small_param_grid,\n",
        "                           scoring='accuracy',\n",
        "                           cv=5,\n",
        "                           verbose=3,\n",
        "                           n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "7cbcb8aa",
      "metadata": {
        "id": "7cbcb8aa"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df[['review']], df['sentiment'], test_size=0.25,\n",
        "                                                    random_state=53)\n",
        "X_train = X_train['review']\n",
        "X_test = X_test['review']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "dfe7dc27",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfe7dc27",
        "outputId": "4dab3e7c-7478-4dce-d304-2d272ab86288"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:705: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('vect',\n",
              "                                        TfidfVectorizer(lowercase=False,\n",
              "                                                        max_features=1000)),\n",
              "                                       ('clf',\n",
              "                                        LogisticRegression(solver='liblinear'))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'clf__C': [1.0, 10.0], 'clf__penalty': ['l1', 'l2'],\n",
              "                         'vect__ngram_range': [(1, 1), (2, 3)],\n",
              "                         'vect__stop_words': [['i', 'me', 'my', 'myself', 'we',\n",
              "                                               'our', 'ours', 'ourselves',\n",
              "                                               'you', \"you're\", \"you've\",\n",
              "                                               \"you'll\", \"you'd\", 'your',\n",
              "                                               'yours', 'yourself',\n",
              "                                               'yourselves', 'he', 'him', 'his',\n",
              "                                               'himself', 'she', \"she's\", 'her',\n",
              "                                               'hers', 'herself', 'it', \"it's\",\n",
              "                                               'its', 'itself', ...],\n",
              "                                              None],\n",
              "                         'vect__tokenizer': [<function tokenizer at 0x7f67fc622560>,\n",
              "                                             <function tokenizer_porter at 0x7f67e9b8e830>]},\n",
              "             scoring='accuracy', verbose=3)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "gs_lr_tfidf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gs_lr_tfidf.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Z80QUaJVWbi",
        "outputId": "5da85bdf-e4e8-4984-c75d-9528dc023e9e"
      },
      "id": "1Z80QUaJVWbi",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf__C': 1.0,\n",
              " 'clf__penalty': 'l1',\n",
              " 'vect__ngram_range': (1, 1),\n",
              " 'vect__stop_words': None,\n",
              " 'vect__tokenizer': <function __main__.tokenizer_porter>}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gs_lr_tfidf.best_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3CumRmQVey9",
        "outputId": "4a48414f-c450-4677-91e8-1799691d5098"
      },
      "id": "c3CumRmQVey9",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8717066666666666"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression('l1', C=1.0, solver = 'liblinear')\n",
        "vectorizer = TfidfVectorizer(strip_accents=None, lowercase=False, preprocessor=None, max_features=1000, ngram_range=(1,1),\n",
        "                             stop_words=None, tokenizer=tokenizer_porter)\n",
        "\n",
        "lr_model = Pipeline([('vect', vectorizer), ('lr', lr)])\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = lr_model.predict(X_test)"
      ],
      "metadata": {
        "id": "VSn_eQ6Lojvf"
      },
      "id": "VSn_eQ6Lojvf",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MeGmradqJ2z",
        "outputId": "baf0aa00-0215-4772-9b30-2e7ce1bdc5ed"
      },
      "id": "6MeGmradqJ2z",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.86      0.87      6232\n",
            "           1       0.87      0.88      0.88      6268\n",
            "\n",
            "    accuracy                           0.87     12500\n",
            "   macro avg       0.87      0.87      0.87     12500\n",
            "weighted avg       0.87      0.87      0.87     12500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_wts = pd.Series(lr.coef_[0,:], vectorizer.get_feature_names_out())\n",
        "feature_wts.sort_values(ascending=False, inplace=True, key = lambda x:np.abs(x))\n",
        "feature_wts.head(50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZzLed1QsX44",
        "outputId": "390d752d-570d-45c7-b4eb-8fe541d2f5fd"
      },
      "id": "JZzLed1QsX44",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "worst        -18.047730\n",
              "wast         -15.108444\n",
              "aw           -14.450483\n",
              "excel         11.381040\n",
              "poorli       -10.762677\n",
              "bore         -10.299208\n",
              "7             10.092335\n",
              "terribl       -9.286034\n",
              "dull          -9.130798\n",
              "bad           -9.106864\n",
              "poor          -8.702173\n",
              "perfect        8.658887\n",
              "great          8.643317\n",
              "lame          -8.203307\n",
              "fail          -8.192961\n",
              "8              8.106995\n",
              "disappoint    -7.993324\n",
              "wors          -7.865706\n",
              "horribl       -7.853387\n",
              "hilari         7.825840\n",
              "superb         7.400235\n",
              "unless        -7.231151\n",
              "noth          -7.039854\n",
              "save          -7.031693\n",
              "ridicul       -6.854794\n",
              "brilliant      6.853368\n",
              "annoy         -6.830216\n",
              "enjoy          6.782606\n",
              "mess          -6.621321\n",
              "lack          -6.396593\n",
              "avoid         -6.307048\n",
              "amaz           6.252759\n",
              "best           6.180539\n",
              "unfortun      -6.165745\n",
              "touch          5.803233\n",
              "fantast        5.666849\n",
              "favorit        5.653430\n",
              "today          5.582319\n",
              "highli         5.577750\n",
              "perfectli      5.452709\n",
              "stupid        -5.452686\n",
              "4             -5.410987\n",
              "suppos        -5.406103\n",
              "minut         -5.325611\n",
              "oh            -5.286377\n",
              "appreci        5.146019\n",
              "predict       -5.036060\n",
              "definit        5.015931\n",
              "sorri         -4.993498\n",
              "cheap         -4.863721\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "43257c35",
      "metadata": {
        "id": "43257c35"
      },
      "outputs": [],
      "source": [
        "count = CountVectorizer(strip_accents=None,\n",
        "                        lowercase=False,\n",
        "                        preprocessor=None, max_features=1000)\n",
        "\n",
        "nb_count = Pipeline([('vect', count),\n",
        "                     ('nb', MultinomialNB())])\n",
        "\n",
        "small_param_grid = {'vect__ngram_range': [(1, 1), (2, 3)],\n",
        "                     'vect__stop_words': [stop, None],\n",
        "                     'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
        "                     'nb__alpha': [0.2,0.4,0.8,1.0]}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gs_nb_count = GridSearchCV(nb_count, small_param_grid,\n",
        "                           scoring='accuracy',\n",
        "                           cv=5,\n",
        "                           verbose=3,\n",
        "                           n_jobs=-1)"
      ],
      "metadata": {
        "id": "r4RPOTFHV9bt"
      },
      "id": "r4RPOTFHV9bt",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "dc2b47e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc2b47e3",
        "outputId": "2659ceb3-2875-4ad2-c00c-00c2855e247e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:705: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('vect',\n",
              "                                        CountVectorizer(lowercase=False,\n",
              "                                                        max_features=1000)),\n",
              "                                       ('nb', MultinomialNB())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'nb__alpha': [0.2, 0.4, 0.8, 1.0],\n",
              "                         'vect__ngram_range': [(1, 1), (2, 3)],\n",
              "                         'vect__stop_words': [['i', 'me', 'my', 'myself', 'we',\n",
              "                                               'our', 'ours', 'ourselves',\n",
              "                                               'you', \"you're\", \"you've\",\n",
              "                                               \"you'll\", \"you'd\", 'your',\n",
              "                                               'yours', 'yourself',\n",
              "                                               'yourselves', 'he', 'him', 'his',\n",
              "                                               'himself', 'she', \"she's\", 'her',\n",
              "                                               'hers', 'herself', 'it', \"it's\",\n",
              "                                               'its', 'itself', ...],\n",
              "                                              None],\n",
              "                         'vect__tokenizer': [<function tokenizer at 0x7fe802bc57a0>,\n",
              "                                             <function tokenizer_porter at 0x7fe7efcf9ef0>]},\n",
              "             scoring='accuracy', verbose=3)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "gs_nb_count.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gs_nb_count.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6bNwre8uTZE",
        "outputId": "dbaab3a7-badf-473c-d58a-77510321a0e1"
      },
      "id": "z6bNwre8uTZE",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'nb__alpha': 0.8,\n",
              " 'vect__ngram_range': (1, 1),\n",
              " 'vect__stop_words': ['i',\n",
              "  'me',\n",
              "  'my',\n",
              "  'myself',\n",
              "  'we',\n",
              "  'our',\n",
              "  'ours',\n",
              "  'ourselves',\n",
              "  'you',\n",
              "  \"you're\",\n",
              "  \"you've\",\n",
              "  \"you'll\",\n",
              "  \"you'd\",\n",
              "  'your',\n",
              "  'yours',\n",
              "  'yourself',\n",
              "  'yourselves',\n",
              "  'he',\n",
              "  'him',\n",
              "  'his',\n",
              "  'himself',\n",
              "  'she',\n",
              "  \"she's\",\n",
              "  'her',\n",
              "  'hers',\n",
              "  'herself',\n",
              "  'it',\n",
              "  \"it's\",\n",
              "  'its',\n",
              "  'itself',\n",
              "  'they',\n",
              "  'them',\n",
              "  'their',\n",
              "  'theirs',\n",
              "  'themselves',\n",
              "  'what',\n",
              "  'which',\n",
              "  'who',\n",
              "  'whom',\n",
              "  'this',\n",
              "  'that',\n",
              "  \"that'll\",\n",
              "  'these',\n",
              "  'those',\n",
              "  'am',\n",
              "  'is',\n",
              "  'are',\n",
              "  'was',\n",
              "  'were',\n",
              "  'be',\n",
              "  'been',\n",
              "  'being',\n",
              "  'have',\n",
              "  'has',\n",
              "  'had',\n",
              "  'having',\n",
              "  'do',\n",
              "  'does',\n",
              "  'did',\n",
              "  'doing',\n",
              "  'a',\n",
              "  'an',\n",
              "  'the',\n",
              "  'and',\n",
              "  'but',\n",
              "  'if',\n",
              "  'or',\n",
              "  'because',\n",
              "  'as',\n",
              "  'until',\n",
              "  'while',\n",
              "  'of',\n",
              "  'at',\n",
              "  'by',\n",
              "  'for',\n",
              "  'with',\n",
              "  'about',\n",
              "  'against',\n",
              "  'between',\n",
              "  'into',\n",
              "  'through',\n",
              "  'during',\n",
              "  'before',\n",
              "  'after',\n",
              "  'above',\n",
              "  'below',\n",
              "  'to',\n",
              "  'from',\n",
              "  'up',\n",
              "  'down',\n",
              "  'in',\n",
              "  'out',\n",
              "  'on',\n",
              "  'off',\n",
              "  'over',\n",
              "  'under',\n",
              "  'again',\n",
              "  'further',\n",
              "  'then',\n",
              "  'once',\n",
              "  'here',\n",
              "  'there',\n",
              "  'when',\n",
              "  'where',\n",
              "  'why',\n",
              "  'how',\n",
              "  'all',\n",
              "  'any',\n",
              "  'both',\n",
              "  'each',\n",
              "  'few',\n",
              "  'more',\n",
              "  'most',\n",
              "  'other',\n",
              "  'some',\n",
              "  'such',\n",
              "  'no',\n",
              "  'nor',\n",
              "  'not',\n",
              "  'only',\n",
              "  'own',\n",
              "  'same',\n",
              "  'so',\n",
              "  'than',\n",
              "  'too',\n",
              "  'very',\n",
              "  's',\n",
              "  't',\n",
              "  'can',\n",
              "  'will',\n",
              "  'just',\n",
              "  'don',\n",
              "  \"don't\",\n",
              "  'should',\n",
              "  \"should've\",\n",
              "  'now',\n",
              "  'd',\n",
              "  'll',\n",
              "  'm',\n",
              "  'o',\n",
              "  're',\n",
              "  've',\n",
              "  'y',\n",
              "  'ain',\n",
              "  'aren',\n",
              "  \"aren't\",\n",
              "  'couldn',\n",
              "  \"couldn't\",\n",
              "  'didn',\n",
              "  \"didn't\",\n",
              "  'doesn',\n",
              "  \"doesn't\",\n",
              "  'hadn',\n",
              "  \"hadn't\",\n",
              "  'hasn',\n",
              "  \"hasn't\",\n",
              "  'haven',\n",
              "  \"haven't\",\n",
              "  'isn',\n",
              "  \"isn't\",\n",
              "  'ma',\n",
              "  'mightn',\n",
              "  \"mightn't\",\n",
              "  'mustn',\n",
              "  \"mustn't\",\n",
              "  'needn',\n",
              "  \"needn't\",\n",
              "  'shan',\n",
              "  \"shan't\",\n",
              "  'shouldn',\n",
              "  \"shouldn't\",\n",
              "  'wasn',\n",
              "  \"wasn't\",\n",
              "  'weren',\n",
              "  \"weren't\",\n",
              "  'won',\n",
              "  \"won't\",\n",
              "  'wouldn',\n",
              "  \"wouldn't\"],\n",
              " 'vect__tokenizer': <function __main__.tokenizer>}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gs_nb_count.best_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_69-azHDWHua",
        "outputId": "684baae2-2aa6-4272-a11f-a524a738acb2"
      },
      "id": "_69-azHDWHua",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8343466666666666"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c_vectorizer = CountVectorizer(strip_accents=None, lowercase=False, preprocessor=None, max_features=1000, ngram_range=(1,1),\n",
        "                               tokenizer = tokenizer, stop_words = stop)\n",
        "\n",
        "nb = MultinomialNB(alpha=0.8)\n",
        "\n",
        "nb_model = Pipeline([('vect', c_vectorizer), ('nb', nb)])\n",
        "\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = nb_model.predict(X_test)"
      ],
      "metadata": {
        "id": "RdTA9H5Jqq_V"
      },
      "id": "RdTA9H5Jqq_V",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKN_M2LAuRUl",
        "outputId": "4f166702-3c0c-4f32-88bf-4c95bb837ae9"
      },
      "id": "yKN_M2LAuRUl",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.83      0.84      6232\n",
            "           1       0.83      0.85      0.84      6268\n",
            "\n",
            "    accuracy                           0.84     12500\n",
            "   macro avg       0.84      0.84      0.84     12500\n",
            "weighted avg       0.84      0.84      0.84     12500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neg_feature_wts = pd.Series(nb.coef_[0,:], c_vectorizer.get_feature_names_out())\n",
        "neg_feature_wts.sort_values(ascending=False, inplace=True, key = lambda x:np.abs(x))\n",
        "neg_feature_wts.head(50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egSfvaI9uYhm",
        "outputId": "a0fd2ef2-c180-45e5-822e-1b565784a44d"
      },
      "id": "egSfvaI9uYhm",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "poorly        -9.423960\n",
              "wasted        -9.261146\n",
              "lame          -9.236413\n",
              "waste         -9.180975\n",
              "mess          -9.044367\n",
              "trash         -8.998397\n",
              "fails         -8.966808\n",
              "badly         -8.954447\n",
              "dumb          -8.800999\n",
              "avoid         -8.800999\n",
              "bored         -8.764782\n",
              "unless        -8.710394\n",
              "dull          -8.710394\n",
              "joke          -8.700815\n",
              "crap          -8.627320\n",
              "flat          -8.618502\n",
              "awful         -8.618502\n",
              "yeah          -8.588236\n",
              "zombie        -8.526309\n",
              "producers     -8.510423\n",
              "plain         -8.506491\n",
              "neither       -8.467995\n",
              "project       -8.464226\n",
              "90            -8.460471\n",
              "horrible      -8.449289\n",
              "ridiculous    -8.441903\n",
              "annoying      -8.416475\n",
              "van           -8.395183\n",
              "filmmakers    -8.381235\n",
              "spent         -8.374334\n",
              "cheap         -8.370901\n",
              "nudity        -8.367480\n",
              "value         -8.367480\n",
              "potential     -8.364071\n",
              "sadly         -8.357286\n",
              "brain         -8.353911\n",
              "weak          -8.347195\n",
              "concept       -8.343854\n",
              "sorry         -8.337205\n",
              "remake        -8.327314\n",
              "biggest       -8.317520\n",
              "cover         -8.311043\n",
              "total         -8.304608\n",
              "decide        -8.288699\n",
              "cheesy        -8.285548\n",
              "terrible      -8.282406\n",
              "15            -8.282406\n",
              "predictable   -8.269937\n",
              "amusing       -8.266844\n",
              "hair          -8.260686\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter, OrderedDict\n",
        "\n",
        "valid_size = int(X_train.shape[0]*0.2)\n",
        "\n",
        "X_train, X_val = X_train.values[:-valid_size], X_train.values[-valid_size:]\n",
        "y_train, y_valid = y_train.values[:-valid_size], y_train.values[-valid_size:]"
      ],
      "metadata": {
        "id": "OKzA4q1BP4Ac"
      },
      "id": "OKzA4q1BP4Ac",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_counts = Counter()\n",
        "\n",
        "for text in X_train:\n",
        "    tokens = tokenizer(text)\n",
        "    token_counts.update(tokens)\n",
        "\n",
        "print('Vocab-size:', len(token_counts))    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrWCo1XLSyfW",
        "outputId": "fd6f4b06-4a76-42fc-9875-7270484a300e"
      },
      "id": "XrWCo1XLSyfW",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab-size: 83824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import vocab\n",
        "\n",
        "sorted_by_freq_tuples = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
        "\n",
        "vocab = vocab(ordered_dict)\n",
        "\n",
        "vocab.insert_token(\"<pad>\", 0)\n",
        "vocab.insert_token(\"<unk>\", 1)\n",
        "vocab.set_default_index(1)\n",
        "\n",
        "print([vocab[token] for token in ['this', 'is', 'an', 'example']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiKQBSwzTtjn",
        "outputId": "797ebd96-6c83-4604-e16f-1f33739e0f96"
      },
      "id": "oiKQBSwzTtjn",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11, 7, 35, 463]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class imdb_dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, text, label):\n",
        "        self.text = text\n",
        "        self.label = label\n",
        "    def __len__(self):\n",
        "        return self.label.size\n",
        "    def __getitem__(self, idx):\n",
        "        return self.text[idx], self.label[idx]        \n"
      ],
      "metadata": {
        "id": "gb6WtrAeUFLV"
      },
      "id": "gb6WtrAeUFLV",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = imdb_dataset(X_train, y_train)\n",
        "valid_dataset = imdb_dataset(X_val, y_valid)\n",
        "test_dataset = imdb_dataset(X_test.values, y_test.values)"
      ],
      "metadata": {
        "id": "JD2c0GxEYekk"
      },
      "id": "JD2c0GxEYekk",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "# device = 'cpu'\n",
        "\n",
        "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
        "label_pipeline = lambda x: 1. if x == 1 else 0.\n",
        "\n",
        "\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list, lengths = [], [], []\n",
        "    for _text, _label in batch:\n",
        "        label_list.append(label_pipeline(_label))\n",
        "        processed_text = torch.tensor(text_pipeline(_text), \n",
        "                                      dtype=torch.int64)\n",
        "        text_list.append(processed_text)\n",
        "        lengths.append(processed_text.size(0))\n",
        "    label_list = torch.tensor(label_list)\n",
        "    lengths = torch.tensor(lengths)\n",
        "    padded_text_list = nn.utils.rnn.pad_sequence(\n",
        "        text_list, batch_first=True)\n",
        "    return padded_text_list.to(device), label_list.to(device), lengths.to(device)"
      ],
      "metadata": {
        "id": "M8-J-8C4YzAr"
      },
      "id": "M8-J-8C4YzAr",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataloader = DataLoader(train_dataset, batch_size=4, shuffle=False, collate_fn=collate_batch)\n",
        "text_batch, label_batch, length_batch = next(iter(dataloader))\n",
        "print(text_batch)\n",
        "print(label_batch)\n",
        "print(length_batch)\n",
        "print(text_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHdoAM2sZXiP",
        "outputId": "b4b45982-d89a-4d67-ffbb-d3f375ea6de1"
      },
      "id": "WHdoAM2sZXiP",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   2,  178, 1081,  ...,    0,    0,    0],\n",
            "        [  11,   20,    7,  ...,    0,    0,    0],\n",
            "        [  45,   21,   39,  ...,    5, 1268,  182],\n",
            "        [2538,   41, 3904,  ...,    0,    0,    0]], device='cuda:0')\n",
            "tensor([1., 1., 1., 1.], device='cuda:0')\n",
            "tensor([168,  83, 549, 104], device='cuda:0')\n",
            "torch.Size([4, 549])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32  \n",
        "\n",
        "train_dl = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                      shuffle=True, collate_fn=collate_batch)\n",
        "valid_dl = DataLoader(valid_dataset, batch_size=batch_size,\n",
        "                      shuffle=False, collate_fn=collate_batch)\n",
        "test_dl = DataLoader(test_dataset, batch_size=batch_size,\n",
        "                     shuffle=False, collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "X3Yw0dkYZvu0"
      },
      "id": "X3Yw0dkYZvu0",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, \n",
        "                                      embed_dim, \n",
        "                                      padding_idx=0) \n",
        "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, \n",
        "                           batch_first=True)\n",
        "        self.fc1 = nn.Linear(rnn_hidden_size, fc_hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, text, lengths):\n",
        "        out = self.embedding(text)\n",
        "        out = nn.utils.rnn.pack_padded_sequence(out, lengths.cpu().numpy(), enforce_sorted=False, batch_first=True)\n",
        "        out, (hidden, cell) = self.rnn(out)\n",
        "        out = hidden[-1, :, :]\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "         \n",
        "vocab_size = len(vocab)\n",
        "embed_dim = 20\n",
        "rnn_hidden_size = 64\n",
        "fc_hidden_size = 64\n",
        "\n",
        "torch.manual_seed(1)\n",
        "model = RNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size) \n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "QUCM44skZ0yV"
      },
      "id": "QUCM44skZ0yV",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader):\n",
        "    model.train()\n",
        "    total_acc, total_loss = 0, 0\n",
        "    for text_batch, label_batch, lengths in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(text_batch, lengths)[:, 0]\n",
        "        loss = loss_fn(pred, label_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
        "        total_loss += loss.item()*label_batch.size(0)\n",
        "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)\n",
        " \n",
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    total_acc, total_loss = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for text_batch, label_batch, lengths in dataloader:\n",
        "            pred = model(text_batch, lengths)[:, 0]\n",
        "            loss = loss_fn(pred, label_batch)\n",
        "            total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
        "            total_loss += loss.item()*label_batch.size(0)\n",
        "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)"
      ],
      "metadata": {
        "id": "BmLVeMQWhDb-"
      },
      "id": "BmLVeMQWhDb-",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10 \n",
        "\n",
        "torch.manual_seed(1)\n",
        " \n",
        "for epoch in range(num_epochs):\n",
        "    acc_train, loss_train = train(train_dl)\n",
        "    acc_valid, loss_valid = evaluate(valid_dl)\n",
        "    print(f'Epoch {epoch} accuracy: {acc_train:.4f} val_accuracy: {acc_valid:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjE1Zb-Sol79",
        "outputId": "4aff33e6-00c9-4605-c3d5-0f30ceb62fa1"
      },
      "id": "RjE1Zb-Sol79",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 accuracy: 0.6151 val_accuracy: 0.6711\n",
            "Epoch 1 accuracy: 0.7227 val_accuracy: 0.6448\n",
            "Epoch 2 accuracy: 0.7713 val_accuracy: 0.7437\n",
            "Epoch 3 accuracy: 0.8345 val_accuracy: 0.8328\n",
            "Epoch 4 accuracy: 0.8447 val_accuracy: 0.8487\n",
            "Epoch 5 accuracy: 0.9017 val_accuracy: 0.8657\n",
            "Epoch 6 accuracy: 0.9254 val_accuracy: 0.8769\n",
            "Epoch 7 accuracy: 0.9386 val_accuracy: 0.8728\n",
            "Epoch 8 accuracy: 0.9558 val_accuracy: 0.8841\n",
            "Epoch 9 accuracy: 0.9685 val_accuracy: 0.8847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_test, _ = evaluate(test_dl)\n",
        "print(f'test_accuracy: {acc_test:.4f}') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnX-UhJi1QSc",
        "outputId": "bf358337-2da3-400e-9ed5-42b9c32ed24d"
      },
      "id": "QnX-UhJi1QSc",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_accuracy: 0.8842\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "pytorch nlp on imdb.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}